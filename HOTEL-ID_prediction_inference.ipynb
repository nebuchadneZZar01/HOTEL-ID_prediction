{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **PREDIZIONE DI HOTEL-ID PER LA PREVENZIONE DEL TRAFFICO DI UMANI (FGVC9 2022) - Notebook di inferenza**\n",
    "\n",
    "**Deep Learning 2022/2023**\n",
    "\n",
    "**Michele Ferro 1000037665**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Caricamento del set di test e di training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michele/.local/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import albumentations as A\n",
    "import albumentations.pytorch as APT\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = os.path.join('/run/media/michele/Archivio/DL_project/hotel-id-to-combat-human-trafficking-2022-fgvc9/')\n",
    "\n",
    "train_path = os.path.join(dataset_path, 'train_images')\n",
    "test_path = os.path.join(dataset_path, 'test_images')\n",
    "val_path = os.path.join(dataset_path, 'val_images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "import albumentations.pytorch as APT\n",
    "\n",
    "IMG_SIZE = 128\n",
    "\n",
    "occlusion_transform = A.CoarseDropout(p=1, max_holes=1, min_height=IMG_SIZE//4, max_height=IMG_SIZE//2,\n",
    "                                      min_width=IMG_SIZE//4, max_width=IMG_SIZE//2, fill_value=(255, 0, 0))\n",
    "\n",
    "# transform used for the obtained training set\n",
    "train_transform = A.Compose([A.HorizontalFlip(p=0.75),\n",
    "                            A.VerticalFlip(p=0.25),\n",
    "                            A.ShiftScaleRotate(p=0.5),\n",
    "                            A.OpticalDistortion(p=0.25),\n",
    "                            A.Perspective(p=0.25),\n",
    "                            A.CoarseDropout(p=0.5, min_holes=1, max_holes=6, \n",
    "                                            min_height=IMG_SIZE//16, max_height=IMG_SIZE//4,\n",
    "                                            min_width=IMG_SIZE//16, max_width=IMG_SIZE//4),\n",
    "                            occlusion_transform,\n",
    "                            A.Resize(IMG_SIZE, IMG_SIZE),\n",
    "                            A.RandomBrightnessContrast(p=0.75),\n",
    "                            A.ToFloat(),\n",
    "                            APT.transforms.ToTensorV2()])\n",
    "\n",
    "# transform used for the validation/test set\n",
    "val_transform = A.Compose([occlusion_transform,\n",
    "                            A.Resize(IMG_SIZE, IMG_SIZE),\n",
    "                            A.ToFloat(),\n",
    "                            APT.transforms.ToTensorV2()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HotelDataset:\n",
    "    def __init__(self, data, transform=None, data_path=train_path, train_val=True):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "        self.data_path = data_path\n",
    "        self.train_val = train_val\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        record = self.data.iloc[idx]\n",
    "\n",
    "        if self.train_val:\n",
    "            image_path = os.path.join(self.data_path,str(record['hotel_id']),record['image_id'])\n",
    "            label = record['hotel_id']\n",
    "        else:\n",
    "            image_path = os.path.join(self.data_path,record['image_id'])\n",
    "        \n",
    "        image = np.array(Image.open(image_path)).astype(np.uint8)\n",
    "\n",
    "        if self.transform:\n",
    "            transformed = self.transform(image=image)\n",
    "            image = transformed['image']\n",
    "        \n",
    "        if self.train_val:\n",
    "            return image, label\n",
    "        else:\n",
    "            return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Definizione del modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import timm\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.optim import SGD\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 - HotelPredictionNetwork v1 - Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HotelPredictionNetworkv1(pl.LightningModule):\n",
    "    def __init__(self, n_classes, embedding_size, extractor_name='efficientnet_b0', lr=0.01, momentum=0.99):\n",
    "        super(HotelPredictionNetworkv1, self).__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.extractor = timm.create_model(extractor_name, num_classes=n_classes, pretrained=True)\n",
    "        in_features = self.extractor.get_classifier().in_features\n",
    "\n",
    "        self.extractor.classifier = nn.Identity()\n",
    "\n",
    "        self.embedding = nn.Linear(in_features, embedding_size)\n",
    "        self.classifier = nn.Linear(embedding_size, n_classes)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.extractor(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.embedding(x)\n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = SGD(self.parameters(), self.hparams.lr, momentum=self.hparams.momentum)\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        x, y = train_batch\n",
    "        output = self.forward(x)\n",
    "        loss = self.criterion(output, y)\n",
    "        self.log('train/loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        x, y = val_batch\n",
    "        output = self.forward(x)\n",
    "        loss = self.criterion(output, y)\n",
    "\n",
    "        acc = accuracy_score(y.cpu(), output.cpu().topk(1).indices)\n",
    "\n",
    "        self.log('val/loss', loss)\n",
    "\n",
    "        return {\n",
    "            'predictions': output.cpu().topk(1).indices,\n",
    "            'labels': y.cpu()\n",
    "        }\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        predictions = np.concatenate([o['predictions'] for o in outputs])\n",
    "        labels = np.concatenate([o['labels'] for o in outputs])\n",
    "\n",
    "        acc = accuracy_score(labels, predictions)\n",
    "\n",
    "        self.log('val/accuracy', acc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 - HotelPredictionNetwork v2 - Metric Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "\n",
    "class ContrastiveLoss(torch.nn.Module):\n",
    "    def __init__(self, m=2):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.m = m\n",
    "\n",
    "    def forward(self, phi_i, phi_j, l_ij):\n",
    "        l_ij = l_ij.float()\n",
    "        d = F.pairwise_distance(phi_i, phi_j)\n",
    "        l = (0.5 * (1 - l_ij) * torch.pow(d, 2)) + (0.5 * l_ij * torch.pow(torch.clamp(self.m - d, min=0),2))\n",
    "\n",
    "        return l.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HotelPredictionNetworkv2(pl.LightningModule):\n",
    "    def __init__(self, extractor_name='efficientnet_b0', lr=0.01, momentum=0.99, margin=2):\n",
    "        super(HotelPredictionNetworkv2, self).__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.embedding = timm.create_model(extractor_name, num_classes=1, pretrained=True)\n",
    "        self.embedding.classifier = nn.Identity()\n",
    "\n",
    "        self.criterion = ContrastiveLoss(margin)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.embedding(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = SGD(self.embedding.parameters(), self.hparams.lr, momentum=self.hparams.momentum)\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        I_i, I_j, l_ij, *_ = train_batch\n",
    "\n",
    "        phi_i = self.embedding(I_i)\n",
    "        phi_j = self.embedding(I_j)\n",
    "\n",
    "        loss = self.criterion(phi_i, phi_j, l_ij)\n",
    "\n",
    "        self.log('train/loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        I_i, I_j, l_ij, *_ = val_batch\n",
    "\n",
    "        phi_i = self.embedding(I_i)\n",
    "        phi_j = self.embedding(I_j)\n",
    "\n",
    "        loss = self.criterion(phi_i, phi_j, l_ij)\n",
    "\n",
    "        self.log('val/loss', loss)\n",
    "\n",
    "        if batch_idx==0:\n",
    "            self.logger.experiment.add_embedding(phi_i, val_batch[3], I_i, global_step=self.global_step)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Caricamento dei modelli da checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv(os.path.join(dataset_path, 'train.csv'))\n",
    "df_val = pd.read_csv(os.path.join(dataset_path, 'val.csv'))\n",
    "df_test = pd.read_csv(os.path.join(dataset_path, 'test.csv'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 - Classificatore `HotelPredictionNetwork`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viene caricato il classificatore addestrato nel notebook di training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes_train = df_train['hotel_id'].max()\n",
    "n_classes_val = df_val['hotel_id'].max()\n",
    "\n",
    "n_classes = max(n_classes_train, n_classes_val) + 1\n",
    "\n",
    "model = HotelPredictionNetwork.load_from_checkpoint('classification_logs/siamese_hotel_id/version_1/checkpoints/epoch=4-step=2795.ckpt', n_classes=n_classes, embedding_size=128)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 - Rete siamese `HotelPredictionNetworkv2`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viene caricata la rete siamese addestrata nel notebook di training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/michele/GitHub/HOTEL-ID_prediction/metric_logs/siamese_hotel_id/version_0/checkpoints/epoch=0-step=559.ckpt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m siamese_hotel_task \u001b[39m=\u001b[39m HotelPredictionNetworkv2\u001b[39m.\u001b[39;49mload_from_checkpoint(\u001b[39m'\u001b[39;49m\u001b[39mmetric_logs/siamese_hotel_id/version_0/checkpoints/epoch=0-step=559.ckpt\u001b[39;49m\u001b[39m'\u001b[39;49m, n_classes\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pytorch_lightning/core/saving.py:137\u001b[0m, in \u001b[0;36mModelIO.load_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_from_checkpoint\u001b[39m(\n\u001b[1;32m     59\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m     65\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Self:  \u001b[39m# type: ignore[valid-type]\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[39m    Primary way of loading a model from a checkpoint. When Lightning saves a checkpoint\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[39m    it stores the arguments passed to ``__init__``  in the checkpoint under ``\"hyper_parameters\"``.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[39m        y_hat = pretrained_model(x)\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m     \u001b[39mreturn\u001b[39;00m _load_from_checkpoint(\n\u001b[1;32m    138\u001b[0m         \u001b[39mcls\u001b[39;49m,\n\u001b[1;32m    139\u001b[0m         checkpoint_path,\n\u001b[1;32m    140\u001b[0m         map_location,\n\u001b[1;32m    141\u001b[0m         hparams_file,\n\u001b[1;32m    142\u001b[0m         strict,\n\u001b[1;32m    143\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    144\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pytorch_lightning/core/saving.py:158\u001b[0m, in \u001b[0;36m_load_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m    156\u001b[0m     map_location \u001b[39m=\u001b[39m cast(_MAP_LOCATION_TYPE, \u001b[39mlambda\u001b[39;00m storage, loc: storage)\n\u001b[1;32m    157\u001b[0m \u001b[39mwith\u001b[39;00m pl_legacy_patch():\n\u001b[0;32m--> 158\u001b[0m     checkpoint \u001b[39m=\u001b[39m pl_load(checkpoint_path, map_location\u001b[39m=\u001b[39;49mmap_location)\n\u001b[1;32m    160\u001b[0m \u001b[39mif\u001b[39;00m hparams_file \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    161\u001b[0m     extension \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(hparams_file)\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/lightning_lite/utilities/cloud_io.py:47\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(path_or_url, map_location)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mhub\u001b[39m.\u001b[39mload_state_dict_from_url(\n\u001b[1;32m     43\u001b[0m         \u001b[39mstr\u001b[39m(path_or_url),\n\u001b[1;32m     44\u001b[0m         map_location\u001b[39m=\u001b[39mmap_location,  \u001b[39m# type: ignore[arg-type] # upstream annotation is not correct\u001b[39;00m\n\u001b[1;32m     45\u001b[0m     )\n\u001b[1;32m     46\u001b[0m fs \u001b[39m=\u001b[39m get_filesystem(path_or_url)\n\u001b[0;32m---> 47\u001b[0m \u001b[39mwith\u001b[39;00m fs\u001b[39m.\u001b[39;49mopen(path_or_url, \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m     48\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mload(f, map_location\u001b[39m=\u001b[39mmap_location)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/fsspec/spec.py:1106\u001b[0m, in \u001b[0;36mAbstractFileSystem.open\u001b[0;34m(self, path, mode, block_size, cache_options, compression, **kwargs)\u001b[0m\n\u001b[1;32m   1104\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1105\u001b[0m     ac \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mautocommit\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_intrans)\n\u001b[0;32m-> 1106\u001b[0m     f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_open(\n\u001b[1;32m   1107\u001b[0m         path,\n\u001b[1;32m   1108\u001b[0m         mode\u001b[39m=\u001b[39;49mmode,\n\u001b[1;32m   1109\u001b[0m         block_size\u001b[39m=\u001b[39;49mblock_size,\n\u001b[1;32m   1110\u001b[0m         autocommit\u001b[39m=\u001b[39;49mac,\n\u001b[1;32m   1111\u001b[0m         cache_options\u001b[39m=\u001b[39;49mcache_options,\n\u001b[1;32m   1112\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   1113\u001b[0m     )\n\u001b[1;32m   1114\u001b[0m     \u001b[39mif\u001b[39;00m compression \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1115\u001b[0m         \u001b[39mfrom\u001b[39;00m \u001b[39mfsspec\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompression\u001b[39;00m \u001b[39mimport\u001b[39;00m compr\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/fsspec/implementations/local.py:175\u001b[0m, in \u001b[0;36mLocalFileSystem._open\u001b[0;34m(self, path, mode, block_size, **kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_mkdir \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m    174\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmakedirs(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parent(path), exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> 175\u001b[0m \u001b[39mreturn\u001b[39;00m LocalFileOpener(path, mode, fs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/fsspec/implementations/local.py:273\u001b[0m, in \u001b[0;36mLocalFileOpener.__init__\u001b[0;34m(self, path, mode, autocommit, fs, compression, **kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompression \u001b[39m=\u001b[39m get_compression(path, compression)\n\u001b[1;32m    272\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocksize \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mDEFAULT_BUFFER_SIZE\n\u001b[0;32m--> 273\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_open()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/fsspec/implementations/local.py:278\u001b[0m, in \u001b[0;36mLocalFileOpener._open\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf\u001b[39m.\u001b[39mclosed:\n\u001b[1;32m    277\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mautocommit \u001b[39mor\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode:\n\u001b[0;32m--> 278\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpath, mode\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmode)\n\u001b[1;32m    279\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompression:\n\u001b[1;32m    280\u001b[0m             compress \u001b[39m=\u001b[39m compr[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompression]\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/michele/GitHub/HOTEL-ID_prediction/metric_logs/siamese_hotel_id/version_0/checkpoints/epoch=0-step=559.ckpt'"
     ]
    }
   ],
   "source": [
    "siamese_hotel_task = HotelPredictionNetworkv2.load_from_checkpoint('metric_logs/siamese_hotel_id/version_0/checkpoints/epoch=4-step=2795.ckpt', n_classes=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Inferenze"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Classificazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, loader):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    preds = []\n",
    "\n",
    "    for batch in loader:\n",
    "        for im in batch:\n",
    "            x = im.to(device)\n",
    "            x = x.unsqueeze(0)\n",
    "            output = model(x)\n",
    "            output = output.detach().to('cpu').numpy()\n",
    "            _, pred = output.max(dim=1)\n",
    "            preds.append(pred)\n",
    "\n",
    "    return np.concatenate(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def predict_image(model, image):\n",
    "    image = Image.open(image)\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    convert_tensor = transforms.ToTensor()\n",
    "    x = convert_tensor(image)\n",
    "    \n",
    "    x = x.to(device)\n",
    "    x = x.unsqueeze(0)\n",
    "\n",
    "    output = model(x)\n",
    "    _, pred = output.max(dim=1)\n",
    "\n",
    "    print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128])\n"
     ]
    }
   ],
   "source": [
    "#im = os.path.join(test_path, 'abc.jpg')\n",
    "im = os.path.join('/run/media/michele/Archivio/DL_project/hotel-id-to-combat-human-trafficking-2022-fgvc9/train_images/2093/000023452.jpg')\n",
    "\n",
    "predict_image(model, im)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 - Estrazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import euclidean_distances\n",
    "from tqdm import tqdm\n",
    "\n",
    "def find_matches(query, base_embeds, base_targets, n_matches=5):\n",
    "    distance_df = pd.DataFrame(index=np.arange(len(base_targets)), data={\"hotel_id\": base_targets})\n",
    "    # calculate euclidean distance of query embeds to all base embeds\n",
    "    distance_df[\"distance\"] = euclidean_distances([query], list(base_embeds))[0]\n",
    "    # sort by distance and hotel_id\n",
    "    distance_df = distance_df.sort_values(by=[\"distance\", \"hotel_id\"], ascending=False).reset_index(drop=True)\n",
    "    # return first 5 different hotel_id codes\n",
    "    return distance_df[\"hotel_id\"].unique()[:n_matches]\n",
    "\n",
    "def extract_representations(model, loader):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    representations = []\n",
    "\n",
    "    for batch in loader:\n",
    "        for im in batch:\n",
    "            x = im.to(device)\n",
    "            x = x.unsqueeze(0)\n",
    "            rep = model(x)\n",
    "            rep = rep.detach().to('cpu').numpy()\n",
    "            representations.append(rep)\n",
    "\n",
    "    return np.concatenate(representations)\n",
    "\n",
    "def predict(base_embeddings_df, test_loader, model):\n",
    "    test_embeds = extract_representations(model, test_loader)\n",
    "    \n",
    "    preds = []\n",
    "    for query_embeds in tqdm(test_embeds, desc=\"Similarity - match finding\"):\n",
    "        tmp = find_matches(query_embeds, \n",
    "                           base_embeddings_df[\"representation\"].values, \n",
    "                           base_embeddings_df[\"hotel_id\"].values)\n",
    "        preds.extend([tmp])\n",
    "        \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>hotel_id</th>\n",
       "      <th>representation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000003767.jpg</td>\n",
       "      <td>100055</td>\n",
       "      <td>[-0.14812493, -0.08349155, -0.13631412, -0.136...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000003768.jpg</td>\n",
       "      <td>100055</td>\n",
       "      <td>[0.15614752, -0.0055957884, 1.3056629, 0.52313...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000019601.jpg</td>\n",
       "      <td>10010</td>\n",
       "      <td>[-0.113037005, -0.04904645, 0.17494473, -0.105...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000019602.jpg</td>\n",
       "      <td>10010</td>\n",
       "      <td>[-0.12619045, -0.08598766, 0.16425446, -0.0969...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000019605.jpg</td>\n",
       "      <td>10010</td>\n",
       "      <td>[-0.06330031, -0.055282604, 0.1714655, 0.35099...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        image_id  hotel_id                                     representation\n",
       "0  000003767.jpg    100055  [-0.14812493, -0.08349155, -0.13631412, -0.136...\n",
       "1  000003768.jpg    100055  [0.15614752, -0.0055957884, 1.3056629, 0.52313...\n",
       "2  000019601.jpg     10010  [-0.113037005, -0.04904645, 0.17494473, -0.105...\n",
       "3  000019602.jpg     10010  [-0.12619045, -0.08598766, 0.16425446, -0.0969...\n",
       "4  000019605.jpg     10010  [-0.06330031, -0.055282604, 0.1714655, 0.35099..."
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_embeddings = pd.read_pickle(os.path.join(dataset_path, 'train_image-embeddings.pkl'))\n",
    "base_embeddings = base_embeddings.drop('representations', axis=1)\n",
    "\n",
    "base_embeddings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_test = HotelDataset(df_test, val_transform, test_path, train_val=False)\n",
    "hotel_test_loader = DataLoader(hotel_test, batch_size=64, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Similarity - match finding: 100%|██████████| 8942/8942 [47:38<00:00,  3.13it/s]  \n"
     ]
    }
   ],
   "source": [
    "preds = predict(base_embeddings, hotel_test_loader, siamese_hotel_task)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>hotel_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.jpg</td>\n",
       "      <td>97165 81171 95635 83939 23976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.jpg</td>\n",
       "      <td>97165 81171 95635 83939 23976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.jpg</td>\n",
       "      <td>97165 81171 95635 83939 23976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100.jpg</td>\n",
       "      <td>97165 81171 95635 83939 23976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000.jpg</td>\n",
       "      <td>97165 81171 95635 83939 23976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id                       hotel_id\n",
       "0     0.jpg  97165 81171 95635 83939 23976\n",
       "1     1.jpg  97165 81171 95635 83939 23976\n",
       "2    10.jpg  97165 81171 95635 83939 23976\n",
       "3   100.jpg  97165 81171 95635 83939 23976\n",
       "4  1000.jpg  97165 81171 95635 83939 23976"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[\"hotel_id\"] = [str(list(l)).strip(\"[]\").replace(\",\", \"\") for l in preds]\n",
    "\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv(os.path.join(dataset_path, 'preds.csv'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
