{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 - Split del training set fornito da Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(dataset_path):\n",
    "    if 'test_images' not in os.listdir(dataset_path):\n",
    "        os.makedirs(os.path.join(dataset_path,'test_images'))\n",
    "\n",
    "    if 'val_images' not in os.listdir(dataset_path):\n",
    "        os.makedirs(os.path.join(dataset_path,'val_images'))\n",
    "\n",
    "    train_path = os.path.join(dataset_path,'train_images')\n",
    "    test_path = os.path.join(dataset_path,'test_images')\n",
    "    val_path = os.path.join(dataset_path,'val_images')\n",
    "\n",
    "    print(train_path)\n",
    "    print(test_path)\n",
    "    print(val_path)\n",
    "\n",
    "    total_files = 0\n",
    "    for folder in os.listdir(train_path):\n",
    "        for file in os.listdir(os.path.join(train_path,folder)):\n",
    "            total_files += 1\n",
    "\n",
    "    train_files = int(total_files * 0.80)                   # training sample has to be 80% of total dataset\n",
    "    test_val_files = total_files - train_files                  # validation/testing sample has to be 20%\n",
    "    \n",
    "    print(total_files)\n",
    "    print('train files are supposed to be', train_files)\n",
    "    print('test files are supposed to be', test_val_files)\n",
    "\n",
    "    cnt = 0\n",
    "    while cnt != test_val_files:\n",
    "        for folder in os.listdir(train_path):\n",
    "            if (len(os.listdir(os.path.join(train_path, folder))) != 0):\n",
    "                file = random.choice(os.listdir(os.path.join(train_path, folder)))\n",
    "                if os.path.isfile(os.path.join(train_path,folder,file)):\n",
    "                    # copies the file in test folder\n",
    "                    shutil.copy(os.path.join(train_path,folder,file), os.path.join(test_path,str(cnt)+'.jpg'))\n",
    "\n",
    "                    # creates a folder with that hotel id (if it doesn't exist) and moves the image file into it\n",
    "                    if folder not in os.listdir(val_path):\n",
    "                        os.makedirs(os.path.join(val_path, folder))\n",
    "                    shutil.move(os.path.join(train_path,folder,file), os.path.join(val_path, folder))\n",
    "\n",
    "                    cnt += 1\n",
    "                    if cnt == test_val_files:\n",
    "                        break\n",
    "\n",
    "\n",
    "    for folder in os.listdir(train_path):\n",
    "        if len(os.listdir(os.path.join(train_path,folder))) == 0:\n",
    "            print(\"Directory\", os.path.join(train_path,folder), \"will be deleted as it's empty\")\n",
    "            os.rmdir(os.path.join(train_path,folder))\n",
    "\n",
    "    return train_path, val_path, test_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_csv(train_path, test_path, val_path):\n",
    "    header_train = ['image_id', 'hotel_id']\n",
    "    \n",
    "    with open(os.path.join(dataset_path,'train.csv'), 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(header_train)\n",
    "        for hotel_id in os.listdir(train_path):\n",
    "            for image_id in os.listdir(os.path.join(train_path, hotel_id)):\n",
    "                writer.writerow([image_id, hotel_id])\n",
    "\n",
    "    with open(os.path.join(dataset_path,'val.csv'), 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(header_train)\n",
    "        for hotel_id in os.listdir(val_path):\n",
    "            for image_id in os.listdir(os.path.join(val_path, hotel_id)):\n",
    "                writer.writerow([image_id, hotel_id])\n",
    "\n",
    "    with open(os.path.join(dataset_path,'test.csv'), 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['image_id'])\n",
    "        for image_id in os.listdir(test_path):\n",
    "            writer.writerow([image_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/run/media/michele/Archivio/DL_project/hotel-id-to-combat-human-trafficking-2022-fgvc9/train_images\n",
      "/run/media/michele/Archivio/DL_project/hotel-id-to-combat-human-trafficking-2022-fgvc9/test_images\n",
      "/run/media/michele/Archivio/DL_project/hotel-id-to-combat-human-trafficking-2022-fgvc9/val_images\n",
      "44703\n",
      "train files are supposed to be 35762\n",
      "test files are supposed to be 8941\n",
      "Directory /run/media/michele/Archivio/DL_project/hotel-id-to-combat-human-trafficking-2022-fgvc9/train_images/111413 will be deleted as it's empty\n",
      "Directory /run/media/michele/Archivio/DL_project/hotel-id-to-combat-human-trafficking-2022-fgvc9/train_images/1122 will be deleted as it's empty\n",
      "Directory /run/media/michele/Archivio/DL_project/hotel-id-to-combat-human-trafficking-2022-fgvc9/train_images/16468 will be deleted as it's empty\n",
      "Directory /run/media/michele/Archivio/DL_project/hotel-id-to-combat-human-trafficking-2022-fgvc9/train_images/11359 will be deleted as it's empty\n",
      "Directory /run/media/michele/Archivio/DL_project/hotel-id-to-combat-human-trafficking-2022-fgvc9/train_images/12178 will be deleted as it's empty\n",
      "Directory /run/media/michele/Archivio/DL_project/hotel-id-to-combat-human-trafficking-2022-fgvc9/train_images/12381 will be deleted as it's empty\n",
      "Directory /run/media/michele/Archivio/DL_project/hotel-id-to-combat-human-trafficking-2022-fgvc9/train_images/12414 will be deleted as it's empty\n",
      "Directory /run/media/michele/Archivio/DL_project/hotel-id-to-combat-human-trafficking-2022-fgvc9/train_images/13132 will be deleted as it's empty\n",
      "Directory /run/media/michele/Archivio/DL_project/hotel-id-to-combat-human-trafficking-2022-fgvc9/train_images/139916 will be deleted as it's empty\n",
      "Directory /run/media/michele/Archivio/DL_project/hotel-id-to-combat-human-trafficking-2022-fgvc9/train_images/18718 will be deleted as it's empty\n",
      "Directory /run/media/michele/Archivio/DL_project/hotel-id-to-combat-human-trafficking-2022-fgvc9/train_images/18855 will be deleted as it's empty\n",
      "Directory /run/media/michele/Archivio/DL_project/hotel-id-to-combat-human-trafficking-2022-fgvc9/train_images/19184 will be deleted as it's empty\n",
      "Directory /run/media/michele/Archivio/DL_project/hotel-id-to-combat-human-trafficking-2022-fgvc9/train_images/197776 will be deleted as it's empty\n",
      "Directory /run/media/michele/Archivio/DL_project/hotel-id-to-combat-human-trafficking-2022-fgvc9/train_images/200002 will be deleted as it's empty\n",
      "Directory /run/media/michele/Archivio/DL_project/hotel-id-to-combat-human-trafficking-2022-fgvc9/train_images/200215 will be deleted as it's empty\n",
      "Directory /run/media/michele/Archivio/DL_project/hotel-id-to-combat-human-trafficking-2022-fgvc9/train_images/201139 will be deleted as it's empty\n",
      "Directory /run/media/michele/Archivio/DL_project/hotel-id-to-combat-human-trafficking-2022-fgvc9/train_images/201241 will be deleted as it's empty\n",
      "Directory /run/media/michele/Archivio/DL_project/hotel-id-to-combat-human-trafficking-2022-fgvc9/train_images/203817 will be deleted as it's empty\n",
      "Directory /run/media/michele/Archivio/DL_project/hotel-id-to-combat-human-trafficking-2022-fgvc9/train_images/206515 will be deleted as it's empty\n",
      "Directory /run/media/michele/Archivio/DL_project/hotel-id-to-combat-human-trafficking-2022-fgvc9/train_images/207157 will be deleted as it's empty\n",
      "Directory /run/media/michele/Archivio/DL_project/hotel-id-to-combat-human-trafficking-2022-fgvc9/train_images/211268 will be deleted as it's empty\n",
      "Directory /run/media/michele/Archivio/DL_project/hotel-id-to-combat-human-trafficking-2022-fgvc9/train_images/22091 will be deleted as it's empty\n",
      "Directory /run/media/michele/Archivio/DL_project/hotel-id-to-combat-human-trafficking-2022-fgvc9/train_images/23460 will be deleted as it's empty\n",
      "Directory /run/media/michele/Archivio/DL_project/hotel-id-to-combat-human-trafficking-2022-fgvc9/train_images/236304 will be deleted as it's empty\n",
      "Directory /run/media/michele/Archivio/DL_project/hotel-id-to-combat-human-trafficking-2022-fgvc9/train_images/25213 will be deleted as it's empty\n",
      "Directory /run/media/michele/Archivio/DL_project/hotel-id-to-combat-human-trafficking-2022-fgvc9/train_images/25543 will be deleted as it's empty\n",
      "Directory /run/media/michele/Archivio/DL_project/hotel-id-to-combat-human-trafficking-2022-fgvc9/train_images/256039 will be deleted as it's empty\n",
      "Directory /run/media/michele/Archivio/DL_project/hotel-id-to-combat-human-trafficking-2022-fgvc9/train_images/28200 will be deleted as it's empty\n",
      "Directory /run/media/michele/Archivio/DL_project/hotel-id-to-combat-human-trafficking-2022-fgvc9/train_images/30552 will be deleted as it's empty\n",
      "Directory /run/media/michele/Archivio/DL_project/hotel-id-to-combat-human-trafficking-2022-fgvc9/train_images/307643 will be deleted as it's empty\n",
      "Directory /run/media/michele/Archivio/DL_project/hotel-id-to-combat-human-trafficking-2022-fgvc9/train_images/308982 will be deleted as it's empty\n",
      "Directory /run/media/michele/Archivio/DL_project/hotel-id-to-combat-human-trafficking-2022-fgvc9/train_images/309234 will be deleted as it's empty\n",
      "Directory /run/media/michele/Archivio/DL_project/hotel-id-to-combat-human-trafficking-2022-fgvc9/train_images/309302 will be deleted as it's empty\n",
      "Directory /run/media/michele/Archivio/DL_project/hotel-id-to-combat-human-trafficking-2022-fgvc9/train_images/309506 will be deleted as it's empty\n",
      "Directory /run/media/michele/Archivio/DL_project/hotel-id-to-combat-human-trafficking-2022-fgvc9/train_images/310041 will be deleted as it's empty\n",
      "Directory /run/media/michele/Archivio/DL_project/hotel-id-to-combat-human-trafficking-2022-fgvc9/train_images/309431 will be deleted as it's empty\n",
      "Directory /run/media/michele/Archivio/DL_project/hotel-id-to-combat-human-trafficking-2022-fgvc9/train_images/3187 will be deleted as it's empty\n",
      "Directory /run/media/michele/Archivio/DL_project/hotel-id-to-combat-human-trafficking-2022-fgvc9/train_images/34250 will be deleted as it's empty\n",
      "Directory /run/media/michele/Archivio/DL_project/hotel-id-to-combat-human-trafficking-2022-fgvc9/train_images/35005 will be deleted as it's empty\n",
      "Directory /run/media/michele/Archivio/DL_project/hotel-id-to-combat-human-trafficking-2022-fgvc9/train_images/35402 will be deleted as it's empty\n",
      "Directory /run/media/michele/Archivio/DL_project/hotel-id-to-combat-human-trafficking-2022-fgvc9/train_images/35579 will be deleted as it's empty\n",
      "Directory /run/media/michele/Archivio/DL_project/hotel-id-to-combat-human-trafficking-2022-fgvc9/train_images/35677 will be deleted as it's empty\n",
      "Directory /run/media/michele/Archivio/DL_project/hotel-id-to-combat-human-trafficking-2022-fgvc9/train_images/396607 will be deleted as it's empty\n",
      "Directory /run/media/michele/Archivio/DL_project/hotel-id-to-combat-human-trafficking-2022-fgvc9/train_images/310554 will be deleted as it's empty\n",
      "Directory /run/media/michele/Archivio/DL_project/hotel-id-to-combat-human-trafficking-2022-fgvc9/train_images/53133 will be deleted as it's empty\n",
      "Directory /run/media/michele/Archivio/DL_project/hotel-id-to-combat-human-trafficking-2022-fgvc9/train_images/63933 will be deleted as it's empty\n",
      "Directory /run/media/michele/Archivio/DL_project/hotel-id-to-combat-human-trafficking-2022-fgvc9/train_images/688391 will be deleted as it's empty\n",
      "Directory /run/media/michele/Archivio/DL_project/hotel-id-to-combat-human-trafficking-2022-fgvc9/train_images/689550 will be deleted as it's empty\n",
      "Directory /run/media/michele/Archivio/DL_project/hotel-id-to-combat-human-trafficking-2022-fgvc9/train_images/723 will be deleted as it's empty\n",
      "Directory /run/media/michele/Archivio/DL_project/hotel-id-to-combat-human-trafficking-2022-fgvc9/train_images/73309 will be deleted as it's empty\n",
      "Directory /run/media/michele/Archivio/DL_project/hotel-id-to-combat-human-trafficking-2022-fgvc9/train_images/74982 will be deleted as it's empty\n",
      "Directory /run/media/michele/Archivio/DL_project/hotel-id-to-combat-human-trafficking-2022-fgvc9/train_images/75014 will be deleted as it's empty\n",
      "Directory /run/media/michele/Archivio/DL_project/hotel-id-to-combat-human-trafficking-2022-fgvc9/train_images/75137 will be deleted as it's empty\n",
      "Directory /run/media/michele/Archivio/DL_project/hotel-id-to-combat-human-trafficking-2022-fgvc9/train_images/47944 will be deleted as it's empty\n",
      "Directory /run/media/michele/Archivio/DL_project/hotel-id-to-combat-human-trafficking-2022-fgvc9/train_images/82686 will be deleted as it's empty\n",
      "Directory /run/media/michele/Archivio/DL_project/hotel-id-to-combat-human-trafficking-2022-fgvc9/train_images/84360 will be deleted as it's empty\n",
      "Directory /run/media/michele/Archivio/DL_project/hotel-id-to-combat-human-trafficking-2022-fgvc9/train_images/97025 will be deleted as it's empty\n",
      "Directory /run/media/michele/Archivio/DL_project/hotel-id-to-combat-human-trafficking-2022-fgvc9/train_images/93959 will be deleted as it's empty\n",
      "Directory /run/media/michele/Archivio/DL_project/hotel-id-to-combat-human-trafficking-2022-fgvc9/train_images/95159 will be deleted as it's empty\n"
     ]
    }
   ],
   "source": [
    "dataset_path = os.path.join('/run/media/michele/Archivio/DL_project/hotel-id-to-combat-human-trafficking-2022-fgvc9/')\n",
    "\n",
    "train_path, val_path, test_path = split_dataset(dataset_path)\n",
    "generate_csv(train_path, test_path, val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: riga 1: nvidia-smi: comando non trovato\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======================= ROCm System Management Interface =======================\n",
      "================================= Product Info =================================\n",
      "GPU[0]\t\t: Card series: \t\tNavi 14 [Radeon RX 5500/5500M / Pro 5500M]\n",
      "GPU[0]\t\t: Card model: \t\t0x04e6\n",
      "GPU[0]\t\t: Card vendor: \t\tAdvanced Micro Devices, Inc. [AMD/ATI]\n",
      "GPU[0]\t\t: Card SKU: \t\tD332P2\n",
      "================================================================================\n",
      "============================= End of ROCm SMI Log ==============================\n"
     ]
    }
   ],
   "source": [
    "!rocm-smi --showproductname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Caricamento del set di test e di training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michele/.local/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import albumentations as A\n",
    "import albumentations.pytorch as APT\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = os.path.join('/run/media/michele/Archivio/DL_project/hotel-id-to-combat-human-trafficking-2022-fgvc9/')\n",
    "\n",
    "train_path = os.path.join(dataset_path, 'train_images')\n",
    "test_path = os.path.join(dataset_path, 'test_images')\n",
    "val_path = os.path.join(dataset_path, 'val_images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "import albumentations.pytorch as APT\n",
    "\n",
    "IMG_SIZE = 128\n",
    "\n",
    "occlusion_transform = A.CoarseDropout(p=1, max_holes=1, min_height=IMG_SIZE//4, max_height=IMG_SIZE//2,\n",
    "                                      min_width=IMG_SIZE//4, max_width=IMG_SIZE//2, fill_value=(255, 0, 0))\n",
    "\n",
    "# transform used for the obtained training set\n",
    "train_transform = A.Compose([A.HorizontalFlip(p=0.75),\n",
    "                            A.VerticalFlip(p=0.25),\n",
    "                            A.ShiftScaleRotate(p=0.5),\n",
    "                            A.OpticalDistortion(p=0.25),\n",
    "                            A.Perspective(p=0.25),\n",
    "                            A.CoarseDropout(p=0.5, min_holes=1, max_holes=6, \n",
    "                                            min_height=IMG_SIZE//16, max_height=IMG_SIZE//4,\n",
    "                                            min_width=IMG_SIZE//16, max_width=IMG_SIZE//4),\n",
    "                            occlusion_transform,\n",
    "                            A.Resize(IMG_SIZE, IMG_SIZE),\n",
    "                            A.RandomBrightnessContrast(p=0.75),\n",
    "                            A.ToFloat(),\n",
    "                            APT.transforms.ToTensorV2()])\n",
    "\n",
    "# transform used for the validation/test set\n",
    "val_transform = A.Compose([occlusion_transform,\n",
    "                            A.Resize(IMG_SIZE, IMG_SIZE),\n",
    "                            A.ToFloat(),\n",
    "                            APT.transforms.ToTensorV2()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HotelDataset:\n",
    "    def __init__(self, _data, _transform=None, _data_path=train_path, _train_val=True):\n",
    "        self.data = _data\n",
    "        self.transform = _transform\n",
    "        self.data_path = _data_path\n",
    "        self.train_val = _train_val\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        record = self.data.iloc[idx]\n",
    "\n",
    "        if self.train_val:\n",
    "            image_path = os.path.join(self.data_path,str(record['hotel_id']),record['image_id'])\n",
    "        else:\n",
    "            image_path = os.path.join(self.data_path,record['image_id'])\n",
    "        \n",
    "        image = np.array(Image.open(image_path)).astype(np.uint8)\n",
    "        label = record['hotel_id']\n",
    "\n",
    "        if self.transform:\n",
    "            transformed = self.transform(image=image)\n",
    "            image = transformed['image']\n",
    "        \n",
    "        if self.train_val:\n",
    "            return image, label\n",
    "        else:\n",
    "            return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100055\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(dataset_path, 'train.csv'))\n",
    "dataset = HotelDataset(df, train_transform, train_path)\n",
    "\n",
    "print(dataset[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "\n",
    "class PairHotelDataset(data.Dataset):\n",
    "    def __init__(self, _data, _transform=None, _data_path=train_path):\n",
    "        self.data = HotelDataset(_data, _transform, _data_path)\n",
    "\n",
    "        #self.class_to_indices = [np.where(self.data[430][1] == label)[0] for label in range(500)]\n",
    "\n",
    "        self.class_to_indices = []\n",
    "\n",
    "        for i in range(len(self.data)):\n",
    "            for label in range(500):\n",
    "                if self.data[i][1] == label:\n",
    "                    class_to_indices.append(self.data[i][0])\n",
    "\n",
    "        self.generate_pairs()\n",
    "\n",
    "    def generate_pairs(self):\n",
    "        print(self.class_to_indices)\n",
    "        self.pair_labels = (np.random.rand(len(self.data))>0.5).astype(int)\n",
    "\n",
    "        self.paired_idx = []\n",
    "\n",
    "        for i, l in enumerate(self.pair_labels):\n",
    "            c1 = self.data[i][1]\n",
    "            if l == 0:\n",
    "                j = np.random.choice(self.class_to_indices[c1])\n",
    "                print(\"if\\n\")\n",
    "            else:\n",
    "                diff_class = np.random.choice(list(set(range(500))-{c1}))\n",
    "                j = np.random.choice(self.class_to_indices[diff_class])\n",
    "                print(\"else\\n\")\n",
    "            self.paired_idx.append(j)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        im1, l1 = self.data[i]\n",
    "        im2, l2 = self.data[self.paired_idx[i]]\n",
    "        l = self.pair_labels[i]\n",
    "\n",
    "        return im1, im2, l, l1, l2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Definizione del modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import timm\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.optim import SGD\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 - HotelPredictionNetwork v1 (only classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HotelPredictionNetwork(pl.LightningModule):\n",
    "    def __init__(self, n_classes, embedding_size, extractor_name='efficientnet_b0'):\n",
    "        super(HotelPredictionNetwork, self).__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.extractor = timm.create_model(extractor_name, num_classes=n_classes, pretrained=True)\n",
    "        in_features = self.extractor.get_classifier().in_features\n",
    "\n",
    "        self.extractor.classifier = nn.Identity()\n",
    "\n",
    "        self.embedding = nn.Linear(in_features, embedding_size)\n",
    "        self.classifier = nn.Linear(embedding_size, n_classes)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.extractor(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def embed_and_classify(self, x):\n",
    "        x = self.forward(x)\n",
    "        return x, self.classifier(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = SGD(self.parameters(), lr=0.001)\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        x, y = train_batch\n",
    "        _, output = self.embed_and_classify(x)\n",
    "        loss = self.criterion(output, y)\n",
    "        self.log('train/loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        x, y = val_batch\n",
    "        output = self.forward(x)\n",
    "\n",
    "        acc = accuracy_score(y.cpu(), output.cpu().topk(1).indices)\n",
    "\n",
    "        self.log('val/accuracy', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 - HotelPredictionNetworkv2 - Metric Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "\n",
    "class ContrastiveLoss(torch.nn.Module):\n",
    "    def __init__(self, m=2):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.m = m\n",
    "\n",
    "    def forward(self, phi_i, phi_j, l_ij):\n",
    "        l_ij = l.ij.float()\n",
    "        d = F.pairwise_distance(phi_i, phi_j)\n",
    "        l = (0.5 * (1 - l_ij) * torch.pow(d, 2)) + (0.5 * l_ij * torch.pow(torch.clamp(self.m - d, min=0),2))\n",
    "\n",
    "        return l.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HotelPredictionNetworkv2(pl.LightningModule):\n",
    "    def __init__(self, n_classes, embedding_size, extractor_name='efficientnet_b0', lr=0.01, momentum=0.99, margin=2):\n",
    "        super(HotelPredictionNetworkv2, self).__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.extractor = timm.create_model(extractor_name, num_classes=n_classes, pretrained=True)\n",
    "        in_features = self.extractor.get_classifier().in_features\n",
    "\n",
    "        self.extractor.classifier = nn.Identity()\n",
    "\n",
    "        self.embedding = nn.Linear(in_features, embedding_size)\n",
    "        self.classifier = nn.Linear(embedding_size, n_classes)\n",
    "        self.criterion = nn.ContrastiveLoss(margin)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.extractor(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def embed_and_classify(self, x):\n",
    "        x = self.forward(x)\n",
    "        return x, self.classifier(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = SGD(self.parameters(), lr=0.001)\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        I_i, I_j, l_ij, *_ = train_batch\n",
    "\n",
    "        phi_i = self.embedding(I_i)\n",
    "        phi_j = self.embedding(I_j)\n",
    "\n",
    "        loss = self.criterion(phi_i, phi_j, l_ij)\n",
    "\n",
    "        self.log('train/loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        I_i, I_j, l_ij, *_ = val_batch\n",
    "\n",
    "        phi_i = self.embedding(I_i)\n",
    "        phi_j = self.embedding(I_j)\n",
    "\n",
    "        loss = self.criterion(phi_i, phi_j, l_ij)\n",
    "\n",
    "        self.log('val/loss')\n",
    "\n",
    "        if batch_idx==0:\n",
    "            self.logger.experiment.add_embedding(phi_i, batch[3], I_i, global_step=self.global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv(os.path.join(dataset_path, 'train.csv'))\n",
    "df_val = pd.read_csv(os.path.join(dataset_path, 'val.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_train = HotelDataset(df_train, train_transform, train_path)\n",
    "hotel_val = HotelDataset(df_val, val_transform, val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_train_loader = DataLoader(hotel_train, batch_size=16, num_workers=6, shuffle=True)\n",
    "hotel_val_loader = DataLoader(hotel_val, batch_size=16, num_workers=6)\n",
    "\n",
    "#print(next(iter(hotel_train_loader)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = next(iter(hotel_train_loader))\n",
    "images = dataiter[0]\n",
    "labels = dataiter[1]\n",
    "\n",
    "# print(images.shape)\n",
    "\n",
    "# for i in range(len(images)):\n",
    "#     for c in range(i):\n",
    "#         plt.imshow(images[i][c])\n",
    "        \n",
    "# print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "690366\n",
      "690365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "n_classes_train = df_train['hotel_id'].max()\n",
    "n_classes_val = df_val['hotel_id'].max()\n",
    "\n",
    "n_classes = max(n_classes_train, n_classes_val) + 1\n",
    "print(n_classes)\n",
    "\n",
    "print(n_classes_val.min(0))\n",
    "\n",
    "model = HotelPredictionNetwork(n_classes, 128)\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=1, accelerator=\"gpu\", devices=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type             | Params\n",
      "------------------------------------------------\n",
      "0 | extractor  | EfficientNet     | 4.0 M \n",
      "1 | embedding  | Linear           | 163 K \n",
      "2 | classifier | Linear           | 89.1 M\n",
      "3 | criterion  | CrossEntropyLoss | 0     \n",
      "------------------------------------------------\n",
      "93.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "93.2 M    Total params\n",
      "372.915   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 2795/2795 [41:58<00:00,  1.11it/s, loss=13.3, v_num=14] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 2795/2795 [41:59<00:00,  1.11it/s, loss=13.3, v_num=14]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, hotel_train_loader, hotel_val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation DataLoader 0: 100%|██████████| 559/559 [06:01<00:00,  1.55it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     Validate metric           DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      val/accuracy                  0.0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'val/accuracy': 0.0}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.validate(model, hotel_val_loader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv(os.path.join(dataset_path, 'train.csv'))\n",
    "df_val = pd.read_csv(os.path.join(dataset_path, 'val.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m hotel_pair_train \u001b[39m=\u001b[39m PairHotelDataset(df_train, train_transform, train_path)\n",
      "Cell \u001b[0;32mIn[65], line 13\u001b[0m, in \u001b[0;36mPairHotelDataset.__init__\u001b[0;34m(self, _data, _transform, _data_path)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata)):\n\u001b[1;32m     12\u001b[0m     \u001b[39mfor\u001b[39;00m label \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m500\u001b[39m):\n\u001b[0;32m---> 13\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata[i][\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m label:\n\u001b[1;32m     14\u001b[0m             class_to_indices\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata[i][\u001b[39m0\u001b[39m])\n\u001b[1;32m     16\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgenerate_pairs()\n",
      "Cell \u001b[0;32mIn[4], line 23\u001b[0m, in \u001b[0;36mHotelDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     20\u001b[0m label \u001b[39m=\u001b[39m record[\u001b[39m'\u001b[39m\u001b[39mhotel_id\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     22\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform:\n\u001b[0;32m---> 23\u001b[0m     transformed \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform(image\u001b[39m=\u001b[39;49mimage)\n\u001b[1;32m     24\u001b[0m     image \u001b[39m=\u001b[39m transformed[\u001b[39m'\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     26\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_val:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/albumentations/core/composition.py:205\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, force_apply, *args, **data)\u001b[0m\n\u001b[1;32m    202\u001b[0m     p\u001b[39m.\u001b[39mpreprocess(data)\n\u001b[1;32m    204\u001b[0m \u001b[39mfor\u001b[39;00m idx, t \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(transforms):\n\u001b[0;32m--> 205\u001b[0m     data \u001b[39m=\u001b[39m t(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mdata)\n\u001b[1;32m    207\u001b[0m     \u001b[39mif\u001b[39;00m check_each_transform:\n\u001b[1;32m    208\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_data_post_transform(data)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/albumentations/core/transforms_interface.py:118\u001b[0m, in \u001b[0;36mBasicTransform.__call__\u001b[0;34m(self, force_apply, *args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m             warn(\n\u001b[1;32m    114\u001b[0m                 \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_class_fullname() \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m could work incorrectly in ReplayMode for other input data\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    115\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m because its\u001b[39m\u001b[39m'\u001b[39m\u001b[39m params depend on targets.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    116\u001b[0m             )\n\u001b[1;32m    117\u001b[0m         kwargs[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave_key][\u001b[39mid\u001b[39m(\u001b[39mself\u001b[39m)] \u001b[39m=\u001b[39m deepcopy(params)\n\u001b[0;32m--> 118\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_with_params(params, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    120\u001b[0m \u001b[39mreturn\u001b[39;00m kwargs\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/albumentations/core/transforms_interface.py:131\u001b[0m, in \u001b[0;36mBasicTransform.apply_with_params\u001b[0;34m(self, params, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m     target_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_target_function(key)\n\u001b[1;32m    130\u001b[0m     target_dependencies \u001b[39m=\u001b[39m {k: kwargs[k] \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_dependence\u001b[39m.\u001b[39mget(key, [])}\n\u001b[0;32m--> 131\u001b[0m     res[key] \u001b[39m=\u001b[39m target_function(arg, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mdict\u001b[39;49m(params, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mtarget_dependencies))\n\u001b[1;32m    132\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    133\u001b[0m     res[key] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/albumentations/augmentations/geometric/transforms.py:323\u001b[0m, in \u001b[0;36mPerspective.apply\u001b[0;34m(self, img, matrix, max_height, max_width, **params)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\u001b[39mself\u001b[39m, img, matrix\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, max_height\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, max_width\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams):\n\u001b[0;32m--> 323\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mperspective(\n\u001b[1;32m    324\u001b[0m         img, matrix, max_width, max_height, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpad_val, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpad_mode, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkeep_size, params[\u001b[39m\"\u001b[39;49m\u001b[39minterpolation\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[1;32m    325\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/albumentations/augmentations/utils.py:122\u001b[0m, in \u001b[0;36mpreserve_channel_dim.<locals>.wrapped_function\u001b[0;34m(img, *args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[1;32m    120\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_function\u001b[39m(img: np\u001b[39m.\u001b[39mndarray, \u001b[39m*\u001b[39margs: P\u001b[39m.\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: P\u001b[39m.\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[1;32m    121\u001b[0m     shape \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39mshape\n\u001b[0;32m--> 122\u001b[0m     result \u001b[39m=\u001b[39m func(img, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    123\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(shape) \u001b[39m==\u001b[39m \u001b[39m3\u001b[39m \u001b[39mand\u001b[39;00m shape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(result\u001b[39m.\u001b[39mshape) \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m    124\u001b[0m         result \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mexpand_dims(result, axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/albumentations/augmentations/geometric/functional.py:467\u001b[0m, in \u001b[0;36mperspective\u001b[0;34m(img, matrix, max_width, max_height, border_val, border_mode, keep_size, interpolation)\u001b[0m\n\u001b[1;32m    458\u001b[0m h, w \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39mshape[:\u001b[39m2\u001b[39m]\n\u001b[1;32m    459\u001b[0m perspective_func \u001b[39m=\u001b[39m _maybe_process_in_chunks(\n\u001b[1;32m    460\u001b[0m     cv2\u001b[39m.\u001b[39mwarpPerspective,\n\u001b[1;32m    461\u001b[0m     M\u001b[39m=\u001b[39mmatrix,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    465\u001b[0m     flags\u001b[39m=\u001b[39minterpolation,\n\u001b[1;32m    466\u001b[0m )\n\u001b[0;32m--> 467\u001b[0m warped \u001b[39m=\u001b[39m perspective_func(img)\n\u001b[1;32m    469\u001b[0m \u001b[39mif\u001b[39;00m keep_size:\n\u001b[1;32m    470\u001b[0m     \u001b[39mreturn\u001b[39;00m resize(warped, h, w, interpolation\u001b[39m=\u001b[39minterpolation)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/albumentations/augmentations/utils.py:208\u001b[0m, in \u001b[0;36m_maybe_process_in_chunks.<locals>.__process_fn\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m    206\u001b[0m     img \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdstack(chunks)\n\u001b[1;32m    207\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 208\u001b[0m     img \u001b[39m=\u001b[39m process_fn(img, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    209\u001b[0m \u001b[39mreturn\u001b[39;00m img\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hotel_pair_train = PairHotelDataset(df_train, train_transform, train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
